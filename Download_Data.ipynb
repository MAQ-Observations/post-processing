{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e598e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900d3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User defined input, specify your wishes below\n",
    "\n",
    "start_date = dt.datetime(2024,1,1)           #Start date (yyyy,mm,dd)\n",
    "end_date = dt.datetime(2024,1,31)            #End date (yyyy,mm,dd)\n",
    "site = 1                                     #Site 1=Veenkampen, 2=Loobos, 3=Amsterdam\n",
    "variables = ['TA_2_1_1',                     #Array of variables to download, see https://maq-observations.nl/instruments/ for a full list, use the 'Steam names', column 1\n",
    "             'TA_1_1_1',\n",
    "             'RH_1_1_1',\n",
    "             'SW_IN_1_1_1',\n",
    "             'SW_OUT_1_1_1',\n",
    "             'LW_IN_1_1_1',\n",
    "             'LW_OUT_1_1_1',\n",
    "             'VIS_1_1_1',\n",
    "             'WS_1_1_1',\n",
    "             'WD_1_1_1',\n",
    "             'P_1_1_1']                                 \n",
    "API_KEY = '<ApiKey>'                              #Put you API key here as a string, see https://maq-observations.nl/api/\n",
    "save_filename = 'MAQ-Observations_request.csv'    #You can define the name of the file you want to save your data to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48874232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing variable TA_2_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48649/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable TA_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48651/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable RH_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48655/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable SW_IN_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48656/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable SW_OUT_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48657/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable LW_IN_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48658/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable LW_OUT_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48659/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable VIS_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48665/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable WS_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48671/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable WD_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48673/measures?from=2024-01-01&to=2024-01-31\n",
      "Processing variable P_1_1_1 at https://maq-observations.nl/wp-json/maq/v1/streams/48703/measures?from=2024-01-01&to=2024-01-31\n",
      "Data successfully saved to MAQ-Observations_request.csv\n",
      "Sample of the data:\n",
      "variable                Timestamp LW_IN_1_1_1 LW_OUT_1_1_1 P_1_1_1 RH_1_1_1  \\\n",
      "0         YYYY-MM-DD HH:MM:SS UTC       W m-2        W m-2      mm        %   \n",
      "1             2024-01-01 00:01:00       334.6        350.1     0.0    74.64   \n",
      "2             2024-01-01 00:02:00       335.4        351.1     0.0    73.95   \n",
      "3             2024-01-01 00:03:00       334.3        349.2     0.0    73.78   \n",
      "4             2024-01-01 00:04:00       334.1        350.3     0.0    73.67   \n",
      "\n",
      "variable SW_IN_1_1_1 SW_OUT_1_1_1 TA_1_1_1 TA_2_1_1 VIS_1_1_1 WD_1_1_1  \\\n",
      "0              W m-2        W m-2       °C       °C         m  degrees   \n",
      "1             -0.852       -5.179     8.59    8.494    5924.0  208.165   \n",
      "2             -0.809       -5.179      8.6    8.534    5955.0  204.405   \n",
      "3             -0.787       -5.211      8.6     8.56    5887.0  201.322   \n",
      "4             -0.819       -5.243     8.61    8.521    5902.0  207.659   \n",
      "\n",
      "variable WS_1_1_1  \n",
      "0           m s-1  \n",
      "1           9.171  \n",
      "2           9.157  \n",
      "3           9.249  \n",
      "4          11.053  \n"
     ]
    }
   ],
   "source": [
    "#Run the request by running this cell (run the cell with the fetch_data function first):\n",
    "\n",
    "fetch_data(start_date,end_date,site,variables,API_KEY,save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd7fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADMIN DEFINED INPUT AND CODE\n",
    "# We recommend to not change the code below. However, you can tailor the code below to change the output structure if you want.\n",
    "\n",
    "\n",
    "def fetch_data(start_date,end_date,site,variables,API_KEY,save_filename):\n",
    "    HOST_KL = 'https://maq-observations.nl'\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': 'ApiKey {}'.format(API_KEY),\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    # Format the dates as strings\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Define the endpoint to fetch metadata (streams)\n",
    "    END_POINT_METADATA = f'/wp-json/maq/v1/sites/{site}/stations/1/streams'\n",
    "    \n",
    "    # Make the GET request to fetch metadata (streams)\n",
    "    response_metadata = requests.get(HOST_KL + END_POINT_METADATA, headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response_metadata.status_code == 200:\n",
    "        data_metadata = response_metadata.json()\n",
    "        \n",
    "        # Convert the metadata to a DataFrame\n",
    "        df_metadata = pd.DataFrame(data_metadata['streams'])\n",
    "        \n",
    "        # Filter the DataFrame for the specified variables\n",
    "        df_filtered = df_metadata[df_metadata['name'].isin(variables)]\n",
    "    \n",
    "        # Prepare to collect units information\n",
    "        units_info = {}\n",
    "\n",
    "        # Loop through each variable and fetch its units information\n",
    "        for _, row in df_filtered.iterrows():\n",
    "            variable_name = row['name']\n",
    "            unit_name = row['unit']['name'] if 'unit' in row and 'name' in row['unit'] else ''\n",
    "            unit_description = row['unit']['description'] if 'unit' in row and 'description' in row['unit'] else ''\n",
    "            \n",
    "            # Store units information in a dictionary for later use\n",
    "            units_info[variable_name] = unit_name if unit_name else unit_description\n",
    "    \n",
    "        # Proceed to fetch time-series data only if there are variables to fetch\n",
    "        if units_info:\n",
    "            # Prepare to collect time-series data\n",
    "            all_data = []\n",
    "    \n",
    "            # Loop through each variable and fetch its time-series data\n",
    "            for variable_name in variables:\n",
    "                stream_id = df_filtered.loc[df_filtered['name'] == variable_name, 'id'].iloc[0]\n",
    "            \n",
    "                # Construct the URL for time-series data for this stream\n",
    "                data_url = f\"{HOST_KL}/wp-json/maq/v1/streams/{stream_id}/measures?from={start_date_str}&to={end_date_str}\"\n",
    "                \n",
    "                print('Processing variable ' + variable_name + \" at \" + data_url)\n",
    "            \n",
    "                # Fetch the time-series data\n",
    "                data_response = requests.get(data_url, headers=headers)\n",
    "\n",
    "                if data_response.status_code == 200:\n",
    "                    data_content = data_response.json()\n",
    "\n",
    "                    # Convert the time-series data to a DataFrame\n",
    "                    if 'measures' in data_content and data_content['measures']:\n",
    "                        time_series_df = pd.DataFrame(data_content['measures'])\n",
    "                        time_series_df['variable'] = variable_name\n",
    "                        all_data.append(time_series_df)\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve data for variable {variable_name}. HTTP Status code: {data_response.status_code}\")\n",
    "\n",
    "            if all_data:\n",
    "                # Concatenate all data into a single DataFrame\n",
    "                final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "                # Pivot the DataFrame to the desired format\n",
    "                final_df_pivoted = final_df.pivot(index='timestamp', columns='variable', values='value')\n",
    "\n",
    "                # Reset index to make timestamp a column instead of index\n",
    "                final_df_pivoted = final_df_pivoted.reset_index()\n",
    "\n",
    "                # Rename the 'timestamp' column to 'Timestamp'\n",
    "                final_df_pivoted = final_df_pivoted.rename(columns={'timestamp': 'Timestamp'})\n",
    "\n",
    "                # Convert 'Timestamp' column to datetime format and format the timestamp\n",
    "                final_df_pivoted['Timestamp'] = pd.to_datetime(final_df_pivoted['Timestamp'], utc=True)\n",
    "                final_df_pivoted['Timestamp'] = final_df_pivoted['Timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                # Insert units as the second row\n",
    "                units_row = ['YYYY-MM-DD HH:MM:SS UTC'] + [units_info[var] for var in final_df_pivoted.columns[1:]]\n",
    "                final_df_pivoted.loc[0] = units_row\n",
    "\n",
    "                # Save the final DataFrame to a CSV file\n",
    "                final_df_pivoted.to_csv(save_filename, index=False)\n",
    "                print(\"Data successfully saved to \"+str(save_filename))\n",
    "\n",
    "                # Print a sample of the data\n",
    "                print(\"Sample of the data:\")\n",
    "                print(final_df_pivoted.head())\n",
    "            else:\n",
    "                print(\"No data was retrieved for the specified variables and date range.\")\n",
    "        else:\n",
    "            print(\"No units information available for the specified variables.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve metadata. HTTP Status code: {response_metadata.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296934a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
